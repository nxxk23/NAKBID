{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nxxk23/NAKBID/blob/main/NINE/web_scrap_drug_center.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umpu8Tqs1GAu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "import tempfile\n",
        "import requests\n",
        "import pandas as pd\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from neo4j import GraphDatabase\n",
        "\n",
        "def login_and_get_download_url(username, password, login_url, download_page):\n",
        "    options = webdriver.ChromeOptions()\n",
        "    options.add_argument(\"--headless\")  # Run in headless mode\n",
        "    driver = webdriver.Chrome(options=options)\n",
        "    wait = WebDriverWait(driver, 10)\n",
        "\n",
        "    try:\n",
        "        driver.get(login_url)\n",
        "        wait.until(EC.presence_of_element_located((By.NAME, \"log\"))).send_keys(username)\n",
        "        wait.until(EC.presence_of_element_located((By.NAME, \"pwd\"))).send_keys(password)\n",
        "        wait.until(EC.element_to_be_clickable((By.ID, \"wp-submit\"))).click()\n",
        "        wait.until(EC.url_changes(login_url))\n",
        "        print(\"✅ ล็อกอินสำเร็จ\")\n",
        "\n",
        "        driver.get(download_page)\n",
        "        download_button = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"a.t-button.t-download\")))\n",
        "        download_url = download_button.get_attribute(\"href\")\n",
        "\n",
        "        if not download_url:\n",
        "            raise ValueError(\"❌ ไม่พบลิงก์ดาวน์โหลด\")\n",
        "\n",
        "        cookies = {cookie['name']: cookie['value'] for cookie in driver.get_cookies()}\n",
        "        return download_url, cookies\n",
        "    except Exception as e:\n",
        "        print(f\"❌ เกิดข้อผิดพลาดขณะล็อกอิน: {e}\")\n",
        "        return None, None\n",
        "    finally:\n",
        "        driver.quit()\n",
        "\n",
        "def download_zip_to_temp(download_url, cookies):\n",
        "    if not download_url:\n",
        "        raise ValueError(\"❌ ไม่มี URL สำหรับดาวน์โหลด\")\n",
        "\n",
        "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "    session = requests.Session()\n",
        "    session.cookies.update(cookies)\n",
        "\n",
        "    response = session.get(download_url, stream=True, headers=headers)\n",
        "    if response.status_code == 200:\n",
        "        temp_zip = tempfile.NamedTemporaryFile(delete=False, suffix=\".zip\")\n",
        "        with open(temp_zip.name, \"wb\") as file:\n",
        "            for chunk in response.iter_content(1024):\n",
        "                file.write(chunk)\n",
        "        print(f\"✅ ดาวน์โหลดสำเร็จ: {temp_zip.name}\")\n",
        "        return temp_zip.name\n",
        "    else:\n",
        "        raise Exception(f\"❌ ดาวน์โหลดล้มเหลว (Error {response.status_code})\")\n",
        "\n",
        "def extract_latest_files(zip_path):\n",
        "    temp_dir = tempfile.mkdtemp()\n",
        "    try:\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(temp_dir)\n",
        "        print(f\"✅ แตกไฟล์ ZIP ไปยัง {temp_dir}\")\n",
        "        return temp_dir\n",
        "    except zipfile.BadZipFile:\n",
        "        print(\"❌ ไฟล์ ZIP เสียหาย\")\n",
        "        return None\n",
        "\n",
        "def load_excel_files(base_path, date_suffix):\n",
        "    files = {\n",
        "        \"GP\": f\"{base_path}/Concept/GP{date_suffix}.xls\",\n",
        "        \"VTM\": f\"{base_path}/Concept/VTM{date_suffix}.xls\",\n",
        "        \"SUBS\": f\"{base_path}/Concept/SUBS{date_suffix}.xls\",\n",
        "        \"TP\": f\"{base_path}/Concept/TP{date_suffix}.xls\",\n",
        "        \"TPU\": f\"{base_path}/Concept/TPU{date_suffix}.xls\",\n",
        "        \"GPU\": f\"{base_path}/Concept/GPU{date_suffix}.xls\",\n",
        "        \"tp_tpu\": f\"{base_path}/Relationship/TPtoTPU{date_suffix}.xls\",\n",
        "        \"gp_tp\": f\"{base_path}/Relationship/GPtoTP{date_suffix}.xls\",\n",
        "        \"vtm_gp\": f\"{base_path}/Relationship/VTMtoGP{date_suffix}.xls\",\n",
        "        \"subs_vtm\": f\"{base_path}/Relationship/SUBStoVTM{date_suffix}.xls\",\n",
        "        \"gp_gpu\": f\"{base_path}/Relationship/GPtoGPU{date_suffix}.xls\"\n",
        "    }\n",
        "\n",
        "    data = {}\n",
        "    for key, path in files.items():\n",
        "        if os.path.exists(path):\n",
        "            try:\n",
        "                data[key] = pd.read_excel(path)\n",
        "                print(f\"✅ โหลดไฟล์ {key} สำเร็จ\")\n",
        "            except Exception as e:\n",
        "                print(f\"❌ โหลดไฟล์ {key} ล้มเหลว: {e}\")\n",
        "\n",
        "    return data\n",
        "\n",
        "def process_data(data):\n",
        "    merge_df = data['tp_tpu'].merge(data['gp_tp'], on='TPID', how='left')\n",
        "    merge_df = merge_df.merge(data['vtm_gp'], on='GPID', how='left')\n",
        "    merge_df = merge_df.merge(data['subs_vtm'], on='VTMID', how='left')\n",
        "    merge_df = merge_df.merge(data['gp_gpu'][['GPID', 'GPUID']], on='GPID', how='left')\n",
        "    merge_df = merge_df.rename(columns={\n",
        "        'GPID': 'TMTID(GP)', 'TPID': 'TMTID(TP)', 'GPUID': 'TMTID(GPU)', 'TPUID': 'TMTID(TPU)',\n",
        "        'VTMID': 'TMTID(VTM)', 'SUBSID': 'TMTID(SUBS)'\n",
        "    })\n",
        "    for key in ['GP', 'TP', 'GPU', 'TPU', 'VTM', 'SUBS']:\n",
        "        merge_df = merge_df.merge(data[key][['TMTID(' + key + ')', 'FSN']], on='TMTID(' + key + ')', how='left')\n",
        "        merge_df = merge_df.rename(columns={'FSN': key + 'NAME'})\n",
        "    merge_df = merge_df.groupby(['TMTID(TPU)', 'TPUNAME','TMTID(TP)', 'TPNAME', 'TMTID(GPU)', 'GPUNAME',\n",
        "                                   'TMTID(GP)', 'GPNAME','TMTID(VTM)','VTMNAME'], as_index=False).agg({\n",
        "        'TMTID(SUBS)': list, 'SUBSNAME': list\n",
        "    })\n",
        "    merge_df = merge_df.rename(columns={'TMTID(SUBS)': 'SUBSID_LIST', 'SUBSNAME': 'SUBS_LIST'})\n",
        "    print(merge_df)\n",
        "    return merge_df\n",
        "\n",
        "def update_neo4j(df):\n",
        "    uri = \"neo4j+s://9bad2ad0.databases.neo4j.io\"\n",
        "    user = \"neo4j\"\n",
        "    password = \"pQdU1M3A-SHlORRRwi6ZOa1lYaEXhf_apicCIkGYfH0\"\n",
        "    driver = GraphDatabase.driver(uri, auth=(user, password))\n",
        "\n",
        "    with driver.session() as session:\n",
        "        session.run(\"\"\"\n",
        "            CREATE CONSTRAINT IF NOT EXISTS ON (n:DRUG) ASSERT n.`TMTID(GP)` IS UNIQUE;\n",
        "            CREATE CONSTRAINT IF NOT EXISTS ON (n:SUBS) ASSERT n.`TMTID(SUBS)` IS UNIQUE;\n",
        "            CREATE CONSTRAINT IF NOT EXISTS ON (n:VTM) ASSERT n.`TMTID(VTM)` IS UNIQUE;\n",
        "            CREATE CONSTRAINT IF NOT EXISTS ON (n:TP) ASSERT n.`TMTID(TP)` IS UNIQUE;\n",
        "            CREATE CONSTRAINT IF NOT EXISTS ON (n:GP) ASSERT n.`TMTID(GP)` IS UNIQUE;\n",
        "        \"\"\")\n",
        "        for _, row in df.iterrows():\n",
        "            session.run(\"\"\"\n",
        "                MERGE (n:DRUG { `TMTID(GP)`: $gp_id })\n",
        "                SET n += { `TMTID(TPU)`: $tpu_id, `TPUNAME`: $tpu_name, `TMTID(TP)`: $tp_id, `TPNAME`: $tp_name,\n",
        "                           `TMTID(GPU)`: $gpu_id, `GPUNAME`: $gpu_name, `GPNAME`: $gp_name,\n",
        "                           `TMTID(VTM)`: $vtm_id, `VTMNAME`: $vtm_name, `SUBSID_LIST`: $subs_list, `SUBS_LIST`: $subs_names }\n",
        "\n",
        "                MERGE (s:SUBS { `TMTID(SUBS)`: $subs_list })\n",
        "                SET s.`SUBSNAME` = $subs_names\n",
        "\n",
        "                MERGE (v:VTM { `TMTID(VTM)`: $vtm_id })\n",
        "                SET v.`VTMNAME` = $vtm_name\n",
        "\n",
        "                MERGE (g:GP { `TMTID(GP)`: $gp_id })\n",
        "                SET g.`GPNAME` = $gp_name\n",
        "\n",
        "                MERGE (t:TP { `TMTID(TP)`: $tp_id })\n",
        "                SET t.`TPNAME` = $tp_name\n",
        "\n",
        "                MERGE (n)-[:HAS_SUBSTANCE]->(s)\n",
        "                MERGE (n)-[:CONTAINS_VTM]->(v)\n",
        "                MERGE (n)-[:HAS_GENERIC_NAME]->(g)\n",
        "                MERGE (g)-[:HAS_TRADE_NAME]->(t)\n",
        "            \"\"\",\n",
        "            gp_id=row['TMTID(GP)'], tpu_id=row['TMTID(TPU)'], tpu_name=row['TPUNAME'],\n",
        "            tp_id=row['TMTID(TP)'], tp_name=row['TPNAME'], gpu_id=row['TMTID(GPU)'],\n",
        "            gpu_name=row['GPUNAME'], gp_name=row['GPNAME'], vtm_id=row['TMTID(VTM)'],\n",
        "            vtm_name=row['VTMNAME'], subs_list=row['SUBSID_LIST'], subs_names=row['SUBS_LIST']\n",
        "        )\n",
        "    driver.close()\n",
        "\n",
        "\n",
        "def main():\n",
        "    username = \"chanatip0615@gmail.com\"\n",
        "    password = \"#chanatip2011\"\n",
        "    login_url = \"https://www.this.or.th/en/account/\"\n",
        "    download_page = \"https://www.this.or.th/en/download/\"\n",
        "\n",
        "    try:\n",
        "        download_url, cookies = login_and_get_download_url(username, password, login_url, download_page)\n",
        "        if not download_url:\n",
        "            return\n",
        "\n",
        "        temp_zip_path = download_zip_to_temp(download_url, cookies)\n",
        "        temp_extract_dir = extract_latest_files(temp_zip_path)\n",
        "\n",
        "        if not temp_extract_dir:\n",
        "            return\n",
        "\n",
        "        data = load_excel_files(temp_extract_dir, \"20250303\")\n",
        "        print(\"this is a data :\",data)\n",
        "        if not data:\n",
        "            return\n",
        "\n",
        "        processed_data = process_data(data)\n",
        "        update_neo4j(processed_data)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ พบข้อผิดพลาด: {e}\")\n",
        "\n",
        "    finally:\n",
        "        if os.path.exists(temp_zip_path):\n",
        "            os.remove(temp_zip_path)\n",
        "            print(\"🗑️ ลบไฟล์ ZIP สำเร็จ\")\n",
        "\n",
        "        if os.path.exists(temp_extract_dir):\n",
        "            shutil.rmtree(temp_extract_dir)\n",
        "            print(\"🗑️ ลบโฟลเดอร์ชั่วคราวสำเร็จ\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}